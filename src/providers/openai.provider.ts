import OpenAI from 'openai';
import {
  ILLMProvider,
  LLMProvider,
  FilterResult,
  FilterByRelevanceOptions,
  SortBySimilarityOptions,
  ApplyNaturalLanguageFilterOptions
} from '../types/llm.types';
import { SimpleProduct } from '../types/product.types';

/**
 * Provider de OpenAI que implementa la interfaz ILLMProvider
 */
export class OpenAIProvider implements ILLMProvider {
  readonly name = LLMProvider.OPENAI;
  private openai: OpenAI;

  constructor() {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      throw new Error('OPENAI_API_KEY no est√° definida en las variables de entorno');
    }
    this.openai = new OpenAI({ apiKey });
  }

  /**
   * Detecta si el modelo es GPT-5 o superior
   */
  private isGPT5OrHigher(model: string): boolean {
    return model.startsWith('gpt-5') || model.startsWith('gpt-6') || model.startsWith('gpt-7');
  }

  /**
   * Detecta si el modelo soporta thinking (o1, o3 series)
   */
  private isThinkingModel(model: string): boolean {
    return model.startsWith('o1') || model.startsWith('o3');
  }

  /**
   * Obtiene la temperatura apropiada seg√∫n el modelo y configuraci√≥n
   */
  private getTemperature(model: string, desiredTemp: number, configSupportsThinking?: boolean, configTemp?: number): number | undefined {
    // Si se especific√≥ temperatura en la configuraci√≥n, usarla
    if (configTemp !== undefined) {
      return configTemp;
    }
    
    // Si se especific√≥ expl√≠citamente que soporta thinking, no usar temperature
    if (configSupportsThinking === true) {
      return undefined;
    }
    
    // Si se especific√≥ expl√≠citamente que NO soporta thinking, usar temperatura deseada
    if (configSupportsThinking === false) {
      return desiredTemp;
    }
    
    // Detecci√≥n autom√°tica basada en el nombre del modelo
    if (this.isThinkingModel(model)) {
      return undefined;
    }
    return this.isGPT5OrHigher(model) ? 1 : desiredTemp;
  }

  /**
   * Obtiene el response_format apropiado seg√∫n el modelo y configuraci√≥n
   */
  private getResponseFormat(model: string, configSupportsThinking?: boolean): { type: 'json_object' } | undefined {
    // Si se especific√≥ expl√≠citamente que soporta thinking, no usar response_format
    if (configSupportsThinking === true) {
      return undefined;
    }
    
    // Si se especific√≥ expl√≠citamente que NO soporta thinking, usar response_format
    if (configSupportsThinking === false) {
      return { type: 'json_object' };
    }
    
    // Detecci√≥n autom√°tica basada en el nombre del modelo
    return this.isThinkingModel(model) ? undefined : { type: 'json_object' };
  }

  /**
   * Limpia la respuesta JSON eliminando markdown si existe
   */
  private cleanJsonResponse(response: string): string {
    let cleaned = response.trim();
    if (cleaned.startsWith('```json')) {
      cleaned = cleaned.replace(/^```json\s*/, '').replace(/\s*```$/, '');
    } else if (cleaned.startsWith('```')) {
      cleaned = cleaned.replace(/^```\s*/, '').replace(/\s*```$/, '');
    }
    return cleaned;
  }

  /**
   * Filtra y rankea productos por relevancia usando OpenAI
   */
  async filterProductsByRelevance(options: FilterByRelevanceOptions): Promise<FilterResult> {
    const { products, query, topN = 15, customFilter, model = 'gpt-4o-mini', supportsThinking, temperature: configTemp } = options;
    
    console.log(`ü§ñ [OpenAI] Filtrando ${products.length} productos...`);
    console.log(`  üîç Query: "${query}"`);
    console.log(`  üéØ Top: ${topN} productos`);
    console.log(`  ü§ñ Modelo: ${model}`);

    try {
      // Optimizaci√≥n: Si hay muchos productos, hacer pre-filtrado simple
      let productsToAnalyze = products;
      if (products.length > 50) {
        console.log(`  ‚ö° Pre-filtrado: ${products.length} ‚Üí 50 productos`);
        const searchWords = query.toLowerCase().split(' ');
        productsToAnalyze = products.filter(p => 
          searchWords.some((word: string) => p.product_name.toLowerCase().includes(word))
        ).slice(0, 50);
        
        if (productsToAnalyze.length === 0) {
          productsToAnalyze = products.slice(0, 50);
        }
      }

      const productsList = productsToAnalyze
        .map((p, i) => `${i + 1}. ${p.product_name.slice(0, 80)} - ‚Ç°${p.price.toLocaleString()}`)
        .join('\n');

      const prompt = `B√∫squeda: "${query}". 

‚ùå EXCLUIR: Accesorios, repuestos, consumibles (brocas, bater√≠as solas, cables)
‚úÖ INCLUIR: Solo el producto principal en diferentes modelos/marcas
${customFilter ? `\n‚ö†Ô∏è FILTRO ADICIONAL: ${customFilter}\n` : ''}

Selecciona los ${topN} M√ÅS relevantes:

${productsList}

Retorna SOLO JSON v√°lido:
{"selected_indices": [n√∫meros del 1 al ${productsToAnalyze.length}], "reasoning": "raz√≥n corta"}`;

      const requestParams: any = {
        model,
        messages: [
          {
            role: 'system',
            content: 'Filtra productos seg√∫n criterios de relevancia. S√© preciso y r√°pido.'
          },
          {
            role: 'user',
            content: prompt
          }
        ]
      };

      const temperature = this.getTemperature(model, 0.3, supportsThinking, configTemp);
      const responseFormat = this.getResponseFormat(model, supportsThinking);
      
      if (temperature !== undefined) requestParams.temperature = temperature;
      if (responseFormat) requestParams.response_format = responseFormat;

      const completion = await this.openai.chat.completions.create(requestParams);

      const choice = completion.choices[0];
      const responseText = choice?.message?.content;
      
      if (!responseText) {
        throw new Error('No se recibi√≥ respuesta de OpenAI');
      }

      // Mostrar reasoning si est√° disponible (modelos con thinking)
      if (this.isThinkingModel(model) && choice?.message && 'reasoning' in choice.message) {
        console.log(`  üß† Reasoning tokens: ${(choice.message as any).reasoning?.length || 'N/A'}`);
      }

      const cleanedResponse = this.cleanJsonResponse(responseText);
      const parsedResult = JSON.parse(cleanedResponse);
      const selectedIndices: number[] = parsedResult.selected_indices || [];

      const filteredProducts = selectedIndices
        .map(idx => productsToAnalyze[idx - 1])
        .filter(p => p !== undefined)
        .slice(0, topN)
        .sort((a, b) => a.price - b.price);

      console.log(`‚úÖ [OpenAI] Seleccion√≥ ${filteredProducts.length} productos`);
      console.log(`  üí° ${parsedResult.reasoning}`);

      return {
        products: filteredProducts,
        summary: parsedResult.reasoning || `Seleccionados ${filteredProducts.length} productos m√°s relevantes`,
        totalFiltered: filteredProducts.length,
        originalCount: products.length
      };
    } catch (error) {
      console.error('‚ùå [OpenAI] Error filtrando:', error);
      return {
        products: products.slice(0, topN),
        summary: 'Error en filtrado, mostrando primeros productos',
        totalFiltered: Math.min(topN, products.length),
        originalCount: products.length
      };
    }
  }

  /**
   * Ordena productos de m√∫ltiples tiendas por similaridad
   */
  async sortProductsBySimilarity(options: SortBySimilarityOptions): Promise<Array<{ store: string; products: SimpleProduct[] }>> {
    const { storeProducts, query, model = 'gpt-4o-mini', supportsThinking, temperature: configTemp } = options;
    
    console.log(`ü§ñ [OpenAI] Ordenando productos por similaridad...`);
    console.log(`  ü§ñ Modelo: ${model}`);

    try {
      const allProducts = storeProducts.flatMap(sp => 
        sp.products.map(p => ({ ...p, storeName: sp.store }))
      );

      if (allProducts.length === 0) {
        console.log(`  ‚ö†Ô∏è  Sin productos para ordenar`);
        return storeProducts;
      }

      const productsToSort = allProducts.slice(0, 50);
      console.log(`  üìä Ordenando ${productsToSort.length} productos...`);

      const productsList = productsToSort.map((p, i) => 
        `${i + 1}. [${p.storeName}] ${p.product_name} - ‚Ç°${p.price.toLocaleString()}`
      ).join('\n');

      const prompt = `Agrupa y ordena estos productos de diferentes tiendas por SIMILARIDAD de t√≠tulo.

B√∫squeda: "${query}"

Productos:
${productsList}

OBJETIVO: Agrupar productos similares (ej: "taladro dewalt 3/8" de diferentes tiendas deben estar juntos).

Retorna SOLO JSON v√°lido:
{
  "ordered_indices": [array de n√∫meros del 1 al ${productsToSort.length}],
  "reasoning": "criterio de agrupaci√≥n usado"
}`;

      const requestParams: any = {
        model,
        messages: [
          {
            role: 'system',
            content: 'Ordena productos por similaridad. Agrupa productos similares juntos.'
          },
          {
            role: 'user',
            content: prompt
          }
        ]
      };

      const temperature = this.getTemperature(model, 0.2, supportsThinking, configTemp);
      const responseFormat = this.getResponseFormat(model, supportsThinking);
      
      if (temperature !== undefined) requestParams.temperature = temperature;
      if (responseFormat) requestParams.response_format = responseFormat;

      const completion = await this.openai.chat.completions.create(requestParams);

      const choice = completion.choices[0];
      const responseText = choice?.message?.content;
      
      if (!responseText) {
        console.warn('‚ö†Ô∏è  No se pudo ordenar, manteniendo orden original');
        return storeProducts;
      }

      // Mostrar reasoning si est√° disponible (modelos con thinking)
      if (this.isThinkingModel(model) && choice?.message && 'reasoning' in choice.message) {
        console.log(`  üß† Reasoning tokens: ${(choice.message as any).reasoning?.length || 'N/A'}`);
      }

      const cleanedResponse = this.cleanJsonResponse(responseText);
      const parsedResult = JSON.parse(cleanedResponse);
      const orderedIndices: number[] = parsedResult.ordered_indices || [];

      const sortedProducts = orderedIndices
        .map(idx => productsToSort[idx - 1])
        .filter(p => p !== undefined);

      console.log(`‚úÖ [OpenAI] Productos ordenados por similaridad`);
      console.log(`  üí° ${parsedResult.reasoning}`);

      const result_by_store: Array<{ store: string; products: SimpleProduct[] }> = [];
      
      for (const sp of storeProducts) {
        const storeOrderedProducts = sortedProducts
          .filter(p => p.storeName === sp.store)
          .map(({ storeName, ...product }) => product as SimpleProduct);
        
        result_by_store.push({
          store: sp.store,
          products: storeOrderedProducts.length > 0 ? storeOrderedProducts : sp.products
        });
      }

      return result_by_store;

    } catch (error) {
      console.error('‚ùå [OpenAI] Error ordenando:', error instanceof Error ? error.message : error);
      return storeProducts;
    }
  }

  /**
   * Aplica filtros inteligentes con lenguaje natural
   */
  async applyNaturalLanguageFilter(options: ApplyNaturalLanguageFilterOptions): Promise<FilterResult> {
    const { products, query, topN = 10, customFilter, model = 'gpt-4o-mini', supportsThinking, temperature: configTemp } = options;
    
    console.log(`ü§ñ [OpenAI] Aplicando filtro: "${query}"`);
    console.log(`  ü§ñ Modelo: ${model}`);

    try {
      const productsToAnalyze = products.slice(0, 50);
      
      const prompt = `Eres un experto en e-commerce. Tu tarea es FILTRAR productos por RELEVANCIA ESTRICTA para la b√∫squeda: "${query}".

üéØ OBJETIVO: Selecciona solo los ${topN} productos M√ÅS RELEVANTES que coincidan DIRECTAMENTE con "${query}".

${customFilter ? `\n‚ö†Ô∏è FILTRO ADICIONAL: ${customFilter}\n` : ''}

‚ùå EXCLUIR PRODUCTOS QUE SON:
- Accesorios del producto buscado (ej: si buscan "taladro", NO incluir "brocas para taladro")
- Repuestos o consumibles (ej: bater√≠as solas, cables, etc.)
- Productos relacionados pero NO el producto principal

‚úÖ INCLUIR SOLO:
- El producto exacto que busca el usuario
- Variantes del mismo producto (diferentes modelos, tama√±os, potencias)
- Diferentes marcas del MISMO tipo de producto

PRODUCTOS:
${productsToAnalyze.map((p, idx) => 
  `${idx + 1}. "${p.product_name}" - ‚Ç°${p.price.toLocaleString()}`
).join('\n')}

Responde SOLO con JSON v√°lido:
{
  "selected_indices": [array de n√∫meros del 1 al ${productsToAnalyze.length}],
  "reasoning": "qu√© productos excluiste y por qu√©"
}`;

      const requestParams: any = {
        model,
        messages: [
          {
            role: 'system',
            content: 'Filtra productos seg√∫n criterios. S√© r√°pido y preciso.'
          },
          {
            role: 'user',
            content: prompt
          }
        ]
      };

      const temperature = this.getTemperature(model, 0.2, supportsThinking, configTemp);
      const responseFormat = this.getResponseFormat(model, supportsThinking);
      
      if (temperature !== undefined) requestParams.temperature = temperature;
      if (responseFormat) requestParams.response_format = responseFormat;

      const completion = await this.openai.chat.completions.create(requestParams);

      const choice = completion.choices[0];
      const responseText = choice?.message?.content;
      
      if (!responseText) {
        throw new Error('No se recibi√≥ respuesta de OpenAI');
      }

      // Mostrar reasoning si est√° disponible (modelos con thinking)
      if (this.isThinkingModel(model) && choice?.message && 'reasoning' in choice.message) {
        console.log(`  üß† Reasoning tokens: ${(choice.message as any).reasoning?.length || 'N/A'}`);
      }

      const cleanedResponse = this.cleanJsonResponse(responseText);
      const parsedResult = JSON.parse(cleanedResponse);
      const selectedIndices: number[] = parsedResult.selected_indices || [];

      const filteredProducts = selectedIndices
        .map(idx => productsToAnalyze[idx - 1])
        .filter(p => p !== undefined);

      console.log(`‚úÖ [OpenAI] filtr√≥: ${filteredProducts.length} productos`);
      console.log(`  üí° ${parsedResult.reasoning}`);

      return {
        products: filteredProducts,
        summary: parsedResult.reasoning || `Filtrados ${filteredProducts.length} productos`,
        totalFiltered: filteredProducts.length,
        originalCount: products.length
      };
    } catch (error) {
      console.error('‚ùå [OpenAI] Error aplicando filtro:', error);
      return {
        products,
        summary: 'Error aplicando filtro, mostrando todos',
        totalFiltered: products.length,
        originalCount: products.length
      };
    }
  }
}

// Singleton instance
let instance: OpenAIProvider | null = null;

export const getOpenAIProvider = (): OpenAIProvider => {
  if (!instance) {
    instance = new OpenAIProvider();
  }
  return instance;
};
